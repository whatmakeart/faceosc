<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Browser Face Capture for Blender</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
    <style>
      body {
        font-family: "Inter", sans-serif;
        touch-action: manipulation; /* Prevents double-tap zoom on mobile */
      }
      #video-container {
        position: relative;
        width: 100%;
        max-width: 640px;
        margin: auto;
      }
      #video {
        width: 100%;
        transform: scaleX(-1); /* Mirror view */
        border-radius: 0.75rem;
      }
      #overlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
      }
    </style>
  </head>
  <body class="bg-gray-900 text-white flex flex-col items-center justify-center min-h-screen p-4">
    <div class="w-full max-w-2xl mx-auto space-y-6">
      <div class="text-center">
        <h1 class="text-3xl font-bold text-cyan-400">Browser Face Capture</h1>
        <p class="text-gray-400">Sending OSC data to Blender via Foscap Addon</p>
      </div>

      <div id="video-container" class="bg-gray-800 rounded-xl shadow-lg overflow-hidden">
        <video id="video" autoplay playsinline></video>
        <canvas id="overlay"></canvas>
      </div>

      <div id="controls" class="bg-gray-800 p-6 rounded-xl shadow-lg space-y-4">
        <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-center">
          <div class="bg-gray-700 p-3 rounded-lg">
            <p class="text-sm text-gray-400">Your Phone's IP</p>
            <p id="local-ip" class="font-mono text-lg text-green-400">Finding...</p>
          </div>
          <div class="bg-gray-700 p-3 rounded-lg">
            <p class="text-sm text-gray-400">Status</p>
            <p id="status" class="font-mono text-lg text-yellow-400">Idle</p>
          </div>
        </div>

        <div class="pt-2">
          <button
            id="start-button"
            class="w-full bg-cyan-500 hover:bg-cyan-600 text-white font-bold py-3 px-4 rounded-lg transition duration-300 text-xl shadow-md">
            Start Capture
          </button>
        </div>
      </div>
    </div>

    <!-- MediaPipe and FaceLandmarker scripts -->
    <script type="module">
      import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

      // --- DOM Elements ---
      const video = document.getElementById("video");
      const startButton = document.getElementById("start-button");
      const statusEl = document.getElementById("status");
      const ipEl = document.getElementById("local-ip");

      // --- Configuration ---
      const BLENDER_PC_IP = "127.0.0.1"; // IMPORTANT: Change this if Blender is on another PC on your WiFi
      const RELAY_PORT = 8080;
      const WEBSOCKET_URL = `ws://${BLENDER_PC_IP}:${RELAY_PORT}`;

      let faceLandmarker;
      let runningMode = "VIDEO";
      let lastVideoTime = -1;
      let streamActive = false;
      let websocket;

      // --- Main Setup Function ---
      async function setup() {
        statusEl.textContent = "Loading Model...";
        const filesetResolver = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
            delegate: "GPU",
          },
          outputFaceBlendshapes: true,
          outputFacialTransformationMatrixes: true,
          runningMode,
          numFaces: 1,
        });
        statusEl.textContent = "Ready";
        startButton.disabled = false;
        startButton.textContent = "Start Capture";
      }

      setup();

      // --- WebSocket Logic ---
      function connectWebSocket() {
        statusEl.textContent = "Connecting...";
        websocket = new WebSocket(WEBSOCKET_URL);

        websocket.onopen = () => {
          console.log("WebSocket connection established.");
          statusEl.textContent = "Streaming...";
          statusEl.classList.remove("text-yellow-400", "text-red-400");
          statusEl.classList.add("text-green-400");
        };

        websocket.onclose = () => {
          console.log("WebSocket connection closed.");
          if (streamActive) {
            statusEl.textContent = "Disconnected";
            statusEl.classList.remove("text-green-400");
            statusEl.classList.add("text-red-400");
            setTimeout(connectWebSocket, 3000);
          }
        };

        websocket.onerror = (error) => {
          console.error("WebSocket Error:", error);
          statusEl.textContent = "Connection Error";
          statusEl.classList.remove("text-green-400");
          statusEl.classList.add("text-red-400");
        };
      }

      // --- Face Tracking Loop ---
      async function predictWebcam() {
        if (video.currentTime !== lastVideoTime) {
          lastVideoTime = video.currentTime;
          const results = faceLandmarker.detectForVideo(video, Date.now());
          if (
            results.faceBlendshapes &&
            results.faceBlendshapes.length > 0 &&
            results.facialTransformationMatrixes[0]
          ) {
            const blendshapes = results.faceBlendshapes[0].categories;
            const transformMatrix = results.facialTransformationMatrixes[0].data;

            const packet = createLiveLinkPacket(blendshapes, transformMatrix);
            if (websocket && websocket.readyState === WebSocket.OPEN) {
              websocket.send(packet);
            }
          }
        }

        if (streamActive) {
          window.requestAnimationFrame(predictWebcam);
        }
      }

      // --- Data Packet Creation ---
      function createLiveLinkPacket(blendshapes, matrix) {
        const blendshapeMap = {
          eyeBlinkLeft: 41,
          eyeBlinkRight: 42,
          eyeLookInLeft: 3,
          eyeLookInRight: 2,
          eyeLookOutLeft: 5,
          eyeLookOutRight: 4,
          eyeWideLeft: 43,
          eyeWideRight: 44,
          jawOpen: 37,
          mouthClose: 27,
          mouthFunnel: 19,
          mouthPucker: 20,
          mouthSmileLeft: 24,
          mouthSmileRight: 23,
        };

        const blendshapeData = new Array(61).fill(0.0);
        for (const shape of blendshapes) {
          const index = blendshapeMap[shape.categoryName];
          if (index !== undefined) {
            blendshapeData[index] = shape.score;
          }
        }

        const [pitch, yaw, roll] = matrixToEuler(matrix);

        // --- Head Rotation Mapping ---
        // This is the CRITICAL part. The Foscap addon reads the rotation data
        // in a very specific, non-standard order and applies negation.
        // We must format our data to match what it expects.
        // Addon logic: rotation_euler = [-data[53], -data[52], -data[54]]
        // To get (Pitch, Roll, Yaw) in Blender, we must provide:
        // data[52] = -Roll
        // data[53] = -Pitch
        // data[54] = -Yaw
        blendshapeData[52] = -roll;
        blendshapeData[53] = -pitch;
        blendshapeData[54] = -yaw;
        // Note: Eye rotation data (55-60) is not provided by MediaPipe and will be zero.

        // --- Construct the binary packet ---
        const deviceName = "Browser";
        // FIXED: Correctly calculate buffer size including the variable device name length
        const buffer = new ArrayBuffer(4 + 37 + 4 + deviceName.length + 17 + 61 * 4);
        const dataView = new DataView(buffer);
        let offset = 0;

        // Version (int32, little-endian) - The addon ignores this, but we include it for format correctness.
        dataView.setInt32(offset, 5, true);
        offset += 4;

        // UUID (dummy string, 37 bytes)
        const uuid = "D9616524-1B12-4264-9A62-2E0E57283584".padEnd(37, "\0");
        for (let i = 0; i < uuid.length; i++) {
          dataView.setUint8(offset + i, uuid.charCodeAt(i));
        }
        offset += 37;

        // Device Name (Length-prefixed string)
        dataView.setInt32(offset, deviceName.length, false); // Big-endian length
        offset += 4;
        for (let i = 0; i < deviceName.length; i++) {
          dataView.setUint8(offset + i, deviceName.charCodeAt(i));
        }
        offset += deviceName.length;

        // Frame Time data (17 bytes, big-endian)
        dataView.setInt32(offset, Math.floor(video.currentTime * 60));
        offset += 4; // Frame Number
        dataView.setFloat32(offset, 0.0);
        offset += 4; // Sub Frame
        dataView.setInt32(offset, 60);
        offset += 4; // Numerator (FPS)
        dataView.setInt32(offset, 1);
        offset += 4; // Denominator
        dataView.setUint8(offset, 61);
        offset += 1; // Blendshape count

        // Blendshapes (61 floats, big-endian)
        for (let i = 0; i < 61; i++) {
          dataView.setFloat32(offset, blendshapeData[i], false);
          offset += 4;
        }

        return buffer;
      }

      // FIXED: Replaced confusing euler conversion with a more standard one.
      function matrixToEuler(matrix) {
        // Extracts Euler angles from a 4x4 column-major matrix
        const sy = Math.sqrt(matrix[0] * matrix[0] + matrix[1] * matrix[1]);
        const singular = sy < 1e-6;
        let x, y, z;
        if (!singular) {
          x = Math.atan2(matrix[6], matrix[10]);
          y = Math.atan2(-matrix[2], sy);
          z = Math.atan2(matrix[1], matrix[0]);
        } else {
          x = Math.atan2(-matrix[9], matrix[5]);
          y = Math.atan2(-matrix[2], sy);
          z = 0;
        }
        // Returns Pitch (x), Yaw (y), Roll (z)
        return [x, y, z];
      }

      // --- Event Listeners ---
      startButton.addEventListener("click", async () => {
        if (streamActive) {
          streamActive = false;
          video.srcObject.getTracks().forEach((track) => track.stop());
          video.srcObject = null;
          startButton.textContent = "Start Capture";
          startButton.classList.remove("bg-red-500", "hover:bg-red-600");
          startButton.classList.add("bg-cyan-500", "hover:bg-cyan-600");
          if (websocket) websocket.close();
          statusEl.textContent = "Idle";
          statusEl.classList.remove("text-green-400", "text-red-400");
          statusEl.classList.add("text-yellow-400");
        } else {
          streamActive = true;
          startButton.textContent = "Stop Capture";
          startButton.classList.remove("bg-cyan-500", "hover:bg-cyan-600");
          startButton.classList.add("bg-red-500", "hover:bg-red-600");

          const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: "user" },
          });
          video.srcObject = stream;
          video.addEventListener("loadeddata", () => {
            connectWebSocket();
            predictWebcam();
          });
        }
      });

      function findLocalIP() {
        try {
          const pc = new RTCPeerConnection({ iceServers: [] });
          pc.createDataChannel("");
          pc.createOffer().then((offer) => pc.setLocalDescription(offer));
          pc.onicecandidate = (ice) => {
            if (ice && ice.candidate && ice.candidate.candidate) {
              const ip = /([0-9]{1,3}(\.[0-9]{1,3}){3})/.exec(ice.candidate.candidate)[1];
              ipEl.textContent = ip;
              pc.onicecandidate = null;
            }
          };
        } catch (e) {
          console.error("Could not find local IP", e);
          ipEl.textContent = "Unknown";
        }
      }

      findLocalIP();
    </script>
  </body>
</html>
